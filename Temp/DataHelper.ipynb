{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from six.moves import cPickle\n",
    "import gzip\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import glob, os, csv, re\n",
    "from collections import Counter\n",
    "from keras.preprocessing import sequence\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_vocab(filelist=\"list_of_grid.txt\", occur=30):\n",
    "    \n",
    "    wordcount={}\n",
    "    list_of_files = [line.rstrip('\\n') for line in open(filelist)]\n",
    "    print(len(list_of_files))\n",
    "    #print(list_of_files)\n",
    "    \n",
    "    \n",
    "    for file in list_of_files:\n",
    "        #print(file) \n",
    "        lines = [line.rstrip('\\n') for line in open(file + \".EGrid\")]\n",
    "        #print(lines)\n",
    "        for line in lines:\n",
    "            ent = line.split()[0]\n",
    "            if ent not in wordcount:\n",
    "                wordcount[ent] = 1\n",
    "            else:\n",
    "                wordcount[ent] += 1\n",
    "    #print(len(wordcount))\n",
    "    #print sorted(wordcount.items(), key=lambda x: x[1])\n",
    "    \n",
    "\n",
    "    wordlist = sorted(wordcount.items(), key=operator.itemgetter(1), reverse=True)    # sorted by value\n",
    "    print(\"Number of entities: \", len(wordlist))\n",
    "    #print(wordlist)\n",
    "    n = (int)(len(wordlist)*occur/100)\n",
    "    print(\"Using\", n, \"for training as\", occur, \"percentage\")\n",
    "\n",
    "    wordlist = wordlist[0:n]\n",
    "    vocabs = []\n",
    "    \n",
    "    for tup in wordlist:\n",
    "        vocabs.append(tup[0])    \n",
    "    vocabs.append(\"oov\") # of our vocabulary word\n",
    "\n",
    "    return vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1378\n",
      "Number of entities:  19903\n",
      "Using 5970 for training as 30 percentage\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['%',\n",
       " 'COMPANY',\n",
       " 'YEAR',\n",
       " 'MR.',\n",
       " 'MILLION',\n",
       " 'CORP.',\n",
       " 'INC.',\n",
       " 'NEW',\n",
       " 'YEARS',\n",
       " 'PRESIDENT',\n",
       " 'MARKET',\n",
       " 'CO.',\n",
       " 'STOCK',\n",
       " 'U.S.',\n",
       " 'YORK',\n",
       " 'SHARE',\n",
       " 'GROUP',\n",
       " 'BUSINESS',\n",
       " 'TIME',\n",
       " 'THERE',\n",
       " 'EXCHANGE',\n",
       " 'ONE',\n",
       " 'SHARES',\n",
       " 'YESTERDAY',\n",
       " 'TRADING',\n",
       " 'CHAIRMAN',\n",
       " 'MONTHS',\n",
       " 'SALES',\n",
       " 'PEOPLE',\n",
       " 'THAT',\n",
       " 'COMPANIES',\n",
       " '$',\n",
       " 'UNIT',\n",
       " 'GOVERNMENT',\n",
       " 'PRICE',\n",
       " 'WEEK',\n",
       " 'BILLION',\n",
       " 'INTEREST',\n",
       " 'PART',\n",
       " 'OFFICIALS',\n",
       " 'MONTH',\n",
       " 'INDUSTRY',\n",
       " 'THIS',\n",
       " 'CENTS',\n",
       " 'BANK',\n",
       " 'INVESTMENT',\n",
       " 'BOARD',\n",
       " 'CONCERN',\n",
       " 'QUARTER',\n",
       " 'SECURITIES',\n",
       " 'VICE',\n",
       " 'SOME',\n",
       " 'ABOUT',\n",
       " 'MONEY',\n",
       " 'ANALYSTS',\n",
       " 'WORLD',\n",
       " 'EARNINGS',\n",
       " 'EXECUTIVE',\n",
       " 'INCOME',\n",
       " 'PRICES',\n",
       " 'PRODUCTS',\n",
       " 'INVESTORS',\n",
       " 'PLAN',\n",
       " 'RATE',\n",
       " 'AMERICAN',\n",
       " 'CAPITAL',\n",
       " 'DIRECTOR',\n",
       " 'OPERATIONS',\n",
       " 'WAY',\n",
       " 'NUMBER',\n",
       " 'MARKETS',\n",
       " 'END',\n",
       " 'OFFICER',\n",
       " 'STATE',\n",
       " 'SALE',\n",
       " 'SPOKESMAN',\n",
       " 'PROGRAM',\n",
       " 'DAYS',\n",
       " 'TODAY',\n",
       " 'REVENUE',\n",
       " 'OCT.',\n",
       " 'VALUE',\n",
       " 'PROFIT',\n",
       " 'SERVICES',\n",
       " 'AGREEMENT',\n",
       " 'DAY',\n",
       " 'MAKER',\n",
       " 'INTERNATIONAL',\n",
       " 'NATIONAL',\n",
       " 'MANAGEMENT',\n",
       " 'PERIOD',\n",
       " 'FIRM',\n",
       " 'ALL',\n",
       " 'MOST',\n",
       " 'DEPARTMENT',\n",
       " 'GROWTH',\n",
       " 'ISSUE',\n",
       " 'CASH',\n",
       " 'JOHN',\n",
       " 'SYSTEM',\n",
       " 'ISSUES',\n",
       " 'TRADE',\n",
       " 'ROBERT',\n",
       " 'HOUSE',\n",
       " 'DEBT',\n",
       " 'HOME',\n",
       " 'SEPTEMBER',\n",
       " 'STAKE',\n",
       " 'ASSETS',\n",
       " 'SERVICE',\n",
       " 'RATES',\n",
       " 'LOSS',\n",
       " 'NEWS',\n",
       " 'THOSE',\n",
       " 'MORE',\n",
       " 'RESEARCH',\n",
       " 'ANALYST',\n",
       " 'PROBLEMS',\n",
       " 'OFFICE',\n",
       " 'CASE',\n",
       " 'RESULTS',\n",
       " 'LAW',\n",
       " 'TIMES',\n",
       " 'GENERAL',\n",
       " 'MOVE',\n",
       " 'FIRST',\n",
       " 'ADDITION',\n",
       " 'COSTS',\n",
       " 'COUNTRY',\n",
       " 'FEDERAL',\n",
       " 'JAPAN',\n",
       " 'STREET',\n",
       " 'WEST',\n",
       " 'WORK',\n",
       " 'WEEKS',\n",
       " 'NOV.',\n",
       " 'TERMS',\n",
       " 'SEPT.',\n",
       " 'OTHERS',\n",
       " 'COURT',\n",
       " 'OFFER',\n",
       " 'INC',\n",
       " 'PROBLEM',\n",
       " 'LEVEL',\n",
       " 'CONTROL',\n",
       " 'EXAMPLE',\n",
       " 'ACQUISITION',\n",
       " 'JAMES',\n",
       " 'FUNDS',\n",
       " 'WALL',\n",
       " 'LINE',\n",
       " 'NATION',\n",
       " 'PRODUCTION',\n",
       " 'INSURANCE',\n",
       " 'AVERAGE',\n",
       " 'REPORT',\n",
       " 'VOLUME',\n",
       " 'PRODUCT',\n",
       " 'MUCH',\n",
       " 'ASSOCIATION',\n",
       " 'TAX',\n",
       " 'RESULT',\n",
       " 'MANY',\n",
       " 'DEVELOPMENT',\n",
       " 'CONGRESS',\n",
       " 'BID',\n",
       " 'AUGUST',\n",
       " 'COMMISSION',\n",
       " 'LOSSES',\n",
       " 'TRANSACTION',\n",
       " 'BANKS',\n",
       " 'MEMBERS',\n",
       " 'SYSTEMS',\n",
       " 'CHANGES',\n",
       " 'AGENCY',\n",
       " 'PLANS',\n",
       " 'LTD.',\n",
       " 'COMMITTEE',\n",
       " 'UNION',\n",
       " 'CORP',\n",
       " 'FRIDAY',\n",
       " 'BILL',\n",
       " 'EXECUTIVES',\n",
       " 'JUNE',\n",
       " 'INCREASE',\n",
       " 'RECORD',\n",
       " 'POWER',\n",
       " 'ECONOMY',\n",
       " 'MARCH',\n",
       " 'BUSINESSES',\n",
       " 'DOLLARS',\n",
       " 'LIFE',\n",
       " 'USE',\n",
       " 'ADMINISTRATION',\n",
       " 'CONTRACT',\n",
       " 'JULY',\n",
       " 'COMPUTER',\n",
       " 'CITY',\n",
       " 'CREDIT',\n",
       " 'AMOUNT',\n",
       " 'DIVISION',\n",
       " 'COST',\n",
       " 'CALIFORNIA',\n",
       " 'ACTION',\n",
       " 'DECISION',\n",
       " 'POLICY',\n",
       " 'FIRMS',\n",
       " 'WASHINGTON',\n",
       " 'SUBSIDIARY',\n",
       " 'INDUSTRIES',\n",
       " 'POINT',\n",
       " 'STOCKS',\n",
       " 'FACT',\n",
       " 'CO',\n",
       " 'AMERICA',\n",
       " 'LOT',\n",
       " 'DEMAND',\n",
       " 'POSITION',\n",
       " 'HALF',\n",
       " 'EFFECT',\n",
       " 'CHICAGO',\n",
       " 'PURCHASE',\n",
       " 'TAKEOVER',\n",
       " 'LOAN',\n",
       " 'TEXAS',\n",
       " 'THINGS',\n",
       " 'EFFORTS',\n",
       " 'DOLLAR',\n",
       " 'BUSH',\n",
       " 'EUROPE',\n",
       " 'MEETING',\n",
       " 'THAN',\n",
       " 'LONDON',\n",
       " 'EMPLOYEES',\n",
       " 'DAVID',\n",
       " 'OCTOBER',\n",
       " 'INVESTOR',\n",
       " 'CHARGE',\n",
       " 'DATA',\n",
       " 'PLANT',\n",
       " 'CHANGE',\n",
       " 'SHAREHOLDERS',\n",
       " 'GAINS',\n",
       " 'TREASURY',\n",
       " 'BONDS',\n",
       " 'ORDER',\n",
       " 'MONDAY',\n",
       " 'EFFORT',\n",
       " 'EQUIPMENT',\n",
       " 'WILLIAM',\n",
       " 'PLACE',\n",
       " 'PAPER',\n",
       " 'STATEMENT',\n",
       " 'DEAL',\n",
       " 'JONES',\n",
       " 'HEALTH',\n",
       " 'OFFICIAL',\n",
       " 'TRADERS',\n",
       " 'SAN',\n",
       " 'DECLINE',\n",
       " 'RICHARD',\n",
       " 'D.',\n",
       " 'APPROVAL',\n",
       " 'MANAGER',\n",
       " 'LEVELS',\n",
       " 'EACH',\n",
       " 'DOW',\n",
       " 'FOOD',\n",
       " 'INDEX',\n",
       " 'CUSTOMERS',\n",
       " 'SERIES',\n",
       " 'SECRETARY',\n",
       " 'INFORMATION',\n",
       " 'COMMUNICATIONS',\n",
       " 'DROP',\n",
       " 'SUPPORT',\n",
       " 'UNITED',\n",
       " 'DEFENSE',\n",
       " 'EQUITY',\n",
       " 'PROPOSAL',\n",
       " 'MARKETING',\n",
       " 'RIGHTS',\n",
       " 'QUESTION',\n",
       " 'LOS',\n",
       " 'PROGRAMS',\n",
       " 'APRIL',\n",
       " 'PROFITS',\n",
       " 'POINTS',\n",
       " 'THE',\n",
       " 'GAIN',\n",
       " 'TRUST',\n",
       " 'OPERATING',\n",
       " 'WORKERS',\n",
       " 'REASON',\n",
       " 'INVESTMENTS',\n",
       " 'PROCESS',\n",
       " 'CONSTRUCTION',\n",
       " 'MANAGERS',\n",
       " 'UNIVERSITY',\n",
       " 'INTERESTS',\n",
       " 'ORDERS',\n",
       " 'OIL',\n",
       " 'DEC.',\n",
       " 'JOB',\n",
       " 'CONSUMER',\n",
       " 'PRESSURE',\n",
       " 'PAYMENTS',\n",
       " 'YEN',\n",
       " 'HEAD',\n",
       " 'FUND',\n",
       " 'RESTRUCTURING',\n",
       " 'REPORTS',\n",
       " 'HOLDERS',\n",
       " 'FINANCE',\n",
       " 'SOUTH',\n",
       " 'PARENT',\n",
       " 'TUESDAY',\n",
       " 'CONCERNS',\n",
       " 'THING',\n",
       " 'PUBLIC',\n",
       " 'RESERVE',\n",
       " 'UNITS',\n",
       " 'ROLE',\n",
       " 'TECHNOLOGY',\n",
       " 'CHARGES',\n",
       " 'NOTES',\n",
       " 'BASIS',\n",
       " 'SOMETHING',\n",
       " 'FAMILY',\n",
       " 'SITUATION',\n",
       " 'STRATEGY',\n",
       " 'COURSE',\n",
       " 'BIG',\n",
       " 'MAY',\n",
       " 'FORCE',\n",
       " 'PERFORMANCE',\n",
       " 'AREAS',\n",
       " 'ANYTHING',\n",
       " 'RISE',\n",
       " 'FIGURES',\n",
       " 'FINANCING',\n",
       " 'A.',\n",
       " 'BRITAIN',\n",
       " 'CONTRACTS',\n",
       " 'SUMMER',\n",
       " 'COMMUNITY',\n",
       " 'DIRECTORS',\n",
       " 'GROUPS',\n",
       " 'MICHAEL',\n",
       " 'BOSTON',\n",
       " 'LOANS',\n",
       " 'AREA',\n",
       " 'PARTS',\n",
       " 'TELEVISION',\n",
       " 'HAND',\n",
       " 'J.',\n",
       " 'IMPACT',\n",
       " 'ESTATE',\n",
       " 'ACTIVITY',\n",
       " 'ANGELES',\n",
       " 'PROTECTION',\n",
       " 'SAVINGS',\n",
       " 'BOND',\n",
       " 'INSTITUTIONS',\n",
       " 'MS.',\n",
       " 'BANKING',\n",
       " 'SENATE',\n",
       " 'AIR',\n",
       " 'AUTO',\n",
       " 'CANADA',\n",
       " 'COMMENT',\n",
       " 'CALIF.',\n",
       " 'LINES',\n",
       " 'RETURN',\n",
       " 'LABOR',\n",
       " 'STATES',\n",
       " 'CENTER',\n",
       " 'KIND',\n",
       " 'ANNOUNCEMENT',\n",
       " 'RULES',\n",
       " 'JANUARY',\n",
       " 'RESPONSE',\n",
       " 'FRANCISCO',\n",
       " 'MEMBER',\n",
       " 'GEORGE',\n",
       " 'MAJORITY',\n",
       " 'PARTY',\n",
       " 'WHITE',\n",
       " 'ACCOUNTS',\n",
       " 'COMPETITION',\n",
       " 'GAS',\n",
       " 'ARTICLE',\n",
       " 'MAKERS',\n",
       " 'GERMANY',\n",
       " 'BUYERS',\n",
       " 'LEADERS',\n",
       " 'NORTH',\n",
       " 'LEADER',\n",
       " 'SPENDING',\n",
       " 'DISTRICT',\n",
       " 'ENERGY',\n",
       " 'HOURS',\n",
       " 'ACCOUNT',\n",
       " 'TELEPHONE',\n",
       " 'CONFERENCE',\n",
       " 'CHEMICAL',\n",
       " 'MANUFACTURING',\n",
       " 'PLC',\n",
       " 'SPRING',\n",
       " 'FUTURE',\n",
       " 'WEDNESDAY',\n",
       " 'INSTITUTE',\n",
       " 'TALKS',\n",
       " 'JR.',\n",
       " 'PARTNER',\n",
       " 'JOURNAL',\n",
       " 'LETTER',\n",
       " 'WAR',\n",
       " 'GOODS',\n",
       " 'NETWORK',\n",
       " 'OFFERING',\n",
       " 'ATTEMPT',\n",
       " 'BROKERAGE',\n",
       " 'SOURCE',\n",
       " 'HOLDINGS',\n",
       " 'LEGISLATION',\n",
       " 'RISK',\n",
       " 'COUNTRIES',\n",
       " 'OPERATION',\n",
       " 'ACTIVITIES',\n",
       " 'FINANCIAL',\n",
       " 'CASES',\n",
       " 'FRANCE',\n",
       " 'DIVIDEND',\n",
       " 'SHAREHOLDER',\n",
       " 'MATTER',\n",
       " 'MACHINES',\n",
       " 'BUDGET',\n",
       " 'VIEW',\n",
       " 'RESERVES',\n",
       " 'BILLS',\n",
       " 'ATTORNEY',\n",
       " 'CAR',\n",
       " 'STAFF',\n",
       " 'U.S',\n",
       " 'INTERVIEW',\n",
       " 'DRUG',\n",
       " 'SESSION',\n",
       " 'NOTHING',\n",
       " 'BASE',\n",
       " 'RIGHT',\n",
       " 'IDEA',\n",
       " 'TWO',\n",
       " 'EVIDENCE',\n",
       " 'SUIT',\n",
       " 'AND',\n",
       " 'TRANSACTIONS',\n",
       " 'CHIEF',\n",
       " 'MEASURE',\n",
       " 'RANGE',\n",
       " 'LYNCH',\n",
       " 'SETTLEMENT',\n",
       " 'RESOURCES',\n",
       " 'MERRILL',\n",
       " 'NET',\n",
       " 'NAME',\n",
       " 'SIDE',\n",
       " 'PETER',\n",
       " 'FALL',\n",
       " 'MOTOR',\n",
       " 'PLANTS',\n",
       " 'TOKYO',\n",
       " 'INDUSTRIAL',\n",
       " 'EXPENSES',\n",
       " 'MERGER',\n",
       " 'THURSDAY',\n",
       " 'BATTLE',\n",
       " 'SENSE',\n",
       " 'DEALERS',\n",
       " 'FACE',\n",
       " 'HISTORY',\n",
       " 'VENTURE',\n",
       " 'CLIENTS',\n",
       " 'PERCENTAGE',\n",
       " 'PROPERTY',\n",
       " 'MOVES',\n",
       " 'MAN',\n",
       " 'BUILDING',\n",
       " 'REST',\n",
       " 'ORGANIZATION',\n",
       " 'SOVIET',\n",
       " 'BANKERS',\n",
       " 'COMPUTERS',\n",
       " 'BUY-OUT',\n",
       " 'DETAILS',\n",
       " 'FORM',\n",
       " 'CLAIMS',\n",
       " 'EARTHQUAKE',\n",
       " 'SIZE',\n",
       " 'R.',\n",
       " 'PARTNERS',\n",
       " 'SECURITY',\n",
       " 'ASSOCIATES',\n",
       " 'CHARLES',\n",
       " 'TEAM',\n",
       " 'FIELD',\n",
       " 'CURRENCY',\n",
       " 'FUTURES',\n",
       " 'WAYS',\n",
       " 'MORGAN',\n",
       " 'MINISTER',\n",
       " 'PRESS',\n",
       " 'ASSET',\n",
       " 'ADVERTISING',\n",
       " 'STANDARD',\n",
       " 'ATTENTION',\n",
       " 'AIRLINES',\n",
       " 'INCREASES',\n",
       " 'MEN',\n",
       " 'PAUL',\n",
       " 'MEDIA',\n",
       " 'MOTORS',\n",
       " 'INFLATION',\n",
       " 'HUTTON',\n",
       " 'ANYONE',\n",
       " 'BUYING',\n",
       " 'OTHER',\n",
       " 'PROJECT',\n",
       " 'ABILITY',\n",
       " 'REP.',\n",
       " 'CONDITIONS',\n",
       " 'DELIVERY',\n",
       " 'BROKERS',\n",
       " 'NOVEMBER',\n",
       " 'MANUFACTURERS',\n",
       " 'SPOKESWOMAN',\n",
       " 'DECEMBER',\n",
       " 'LEHMAN',\n",
       " 'TERM',\n",
       " 'ACT',\n",
       " 'SIGN',\n",
       " 'ITEMS',\n",
       " 'STRENGTH',\n",
       " 'LITTLE',\n",
       " 'TREND',\n",
       " 'STEP',\n",
       " 'SECTOR',\n",
       " 'PAYMENT',\n",
       " 'SCHOOL',\n",
       " 'SHEARSON',\n",
       " 'ESTIMATES',\n",
       " 'SMITH',\n",
       " 'CARS',\n",
       " 'MORTGAGE',\n",
       " 'POLICIES',\n",
       " 'THREE',\n",
       " 'TV',\n",
       " 'TOTAL',\n",
       " 'POST',\n",
       " 'THOMAS',\n",
       " 'SPACE',\n",
       " 'OPPORTUNITY',\n",
       " 'QUESTIONS',\n",
       " 'BENEFITS',\n",
       " 'HANDS',\n",
       " 'POOR',\n",
       " 'PORTFOLIO',\n",
       " 'DEBATE',\n",
       " 'OPTIONS',\n",
       " 'NEWSPAPER',\n",
       " 'SUPPLY',\n",
       " 'ELECTRONICS',\n",
       " 'INSTANCE',\n",
       " 'REGULATORS',\n",
       " 'ANOTHER',\n",
       " 'ELECTRIC',\n",
       " 'BANKRUPTCY',\n",
       " 'PROJECTS',\n",
       " 'MARKS',\n",
       " 'MARK',\n",
       " 'MORNING',\n",
       " 'EUROPEAN',\n",
       " 'AIRLINE',\n",
       " 'DATE',\n",
       " 'GERMAN',\n",
       " 'PRACTICE',\n",
       " 'TRANSPORTATION',\n",
       " 'BROTHERS',\n",
       " 'PROCEEDS',\n",
       " 'SUCCESS',\n",
       " 'TAXES',\n",
       " 'PURCHASES',\n",
       " 'BRITISH',\n",
       " 'E.',\n",
       " 'CONSUMERS',\n",
       " 'AFFAIRS',\n",
       " 'PERSON',\n",
       " 'NEGOTIATIONS',\n",
       " 'POSITIONS',\n",
       " 'CHANCE',\n",
       " 'PRODUCERS',\n",
       " 'CAMPAIGN',\n",
       " 'STANLEY',\n",
       " 'PORTION',\n",
       " 'ONES',\n",
       " 'MINORITY',\n",
       " 'M.',\n",
       " 'DEFICIT',\n",
       " 'FORD',\n",
       " 'OWN',\n",
       " 'WOMEN',\n",
       " '..',\n",
       " 'EVERYONE',\n",
       " 'RELATIONS',\n",
       " 'DECADE',\n",
       " 'AUCTION',\n",
       " 'STRIKE',\n",
       " 'L.',\n",
       " 'STORY',\n",
       " 'FLOOR',\n",
       " 'APPROACH',\n",
       " 'NIGHT',\n",
       " 'JOBS',\n",
       " 'EAST',\n",
       " 'COMPETITORS',\n",
       " 'QUALITY',\n",
       " 'ENTERTAINMENT',\n",
       " 'REDUCTION',\n",
       " 'EXPECTATIONS',\n",
       " 'CLOSE',\n",
       " 'ADVISER',\n",
       " 'LAWYERS',\n",
       " 'JUSTICE',\n",
       " 'TROUBLE',\n",
       " 'VOTE',\n",
       " 'CONTRAST',\n",
       " 'ECONOMISTS',\n",
       " 'YIELD',\n",
       " 'FIGURE',\n",
       " 'CAPACITY',\n",
       " 'CHILDREN',\n",
       " 'PACKAGE',\n",
       " 'CUTS',\n",
       " 'ENGINEERING',\n",
       " 'FACILITIES',\n",
       " 'STANDARDS',\n",
       " 'DISCUSSIONS',\n",
       " 'SPECULATION',\n",
       " 'ALAN',\n",
       " 'SOURCES',\n",
       " 'TOMORROW',\n",
       " 'OWNERS',\n",
       " 'FEES',\n",
       " 'OWNER',\n",
       " 'STEEL',\n",
       " 'LIST',\n",
       " 'AUTHORITY',\n",
       " 'AMERICANS',\n",
       " 'SELLING',\n",
       " 'FLOW',\n",
       " 'SHOW',\n",
       " 'STUDY',\n",
       " 'PAST',\n",
       " 'AID',\n",
       " 'STORES',\n",
       " 'PACIFIC',\n",
       " 'COMMERCE',\n",
       " 'PARTNERSHIP',\n",
       " 'ENVIRONMENT',\n",
       " 'DISCOUNT',\n",
       " 'EVERYTHING',\n",
       " 'JUDGE',\n",
       " 'MATERIALS',\n",
       " 'GOLDMAN',\n",
       " 'AGE',\n",
       " 'TARGET',\n",
       " 'NEED',\n",
       " 'HIGH',\n",
       " 'ACQUISITIONS',\n",
       " 'FILING',\n",
       " 'HURRICANE',\n",
       " 'CHEMICALS',\n",
       " 'RESTRICTIONS',\n",
       " 'GAME',\n",
       " 'LAWS',\n",
       " 'DIRECTION',\n",
       " 'ECONOMIST',\n",
       " 'MAGAZINE',\n",
       " 'COUNCIL',\n",
       " 'RETURNS',\n",
       " 'PARTIES',\n",
       " 'HOLDING',\n",
       " 'INDIVIDUALS',\n",
       " 'INVESTIGATION',\n",
       " '1\\\\',\n",
       " 'JUNK',\n",
       " 'OPTION',\n",
       " 'TEST',\n",
       " 'TRIAL',\n",
       " 'PRODUCER',\n",
       " 'EASTERN',\n",
       " 'DAMAGE',\n",
       " 'EXPERIENCE',\n",
       " 'EXPANSION',\n",
       " 'MEETINGS',\n",
       " 'REQUIREMENTS',\n",
       " 'FACTORS',\n",
       " 'LACK',\n",
       " 'C.',\n",
       " 'FACILITY',\n",
       " 'CHAPTER',\n",
       " 'EVENTS',\n",
       " 'OWNERSHIP',\n",
       " 'ST.',\n",
       " 'NOTE',\n",
       " 'GOAL',\n",
       " 'GIANT',\n",
       " 'REVIEW',\n",
       " 'JAPANESE',\n",
       " 'DIFFERENCE',\n",
       " 'WEAKNESS',\n",
       " 'PAINEWEBBER',\n",
       " 'PROVISION',\n",
       " 'BOOK',\n",
       " 'HUGO',\n",
       " 'ESTIMATE',\n",
       " 'PETROLEUM',\n",
       " 'PARIS',\n",
       " 'BUT',\n",
       " 'RISKS',\n",
       " 'NOW',\n",
       " 'SOMEONE',\n",
       " 'LAWMAKERS',\n",
       " 'VOLATILITY',\n",
       " 'OPINION',\n",
       " 'IMAGE',\n",
       " 'AFTERNOON',\n",
       " 'SURVEY',\n",
       " 'SACHS',\n",
       " 'SECTION',\n",
       " 'DEBENTURES',\n",
       " 'CONSULTANT',\n",
       " 'MEASURES',\n",
       " 'RECESSION',\n",
       " 'DISTRIBUTION',\n",
       " 'TRADES',\n",
       " 'PROPOSALS',\n",
       " 'CRASH',\n",
       " 'TREATMENT',\n",
       " 'WOMAN',\n",
       " 'CARE',\n",
       " 'ACCOUNTING',\n",
       " 'FORCES',\n",
       " 'THESE',\n",
       " 'SIGNS',\n",
       " 'HOUSES',\n",
       " 'STEPS',\n",
       " 'BALANCE',\n",
       " 'ACCESS',\n",
       " 'DREXEL',\n",
       " 'ACTIONS',\n",
       " 'LAWYER',\n",
       " 'PROPERTIES',\n",
       " 'DISPUTE',\n",
       " 'VENTURES',\n",
       " 'SEN.',\n",
       " 'CLOSING',\n",
       " 'PRIME',\n",
       " 'LOUIS',\n",
       " 'B.',\n",
       " 'SAFETY',\n",
       " 'HOUSING',\n",
       " 'STATISTICS',\n",
       " 'CHAIN',\n",
       " 'HONG',\n",
       " 'N.J.',\n",
       " 'AD',\n",
       " 'PRACTICES',\n",
       " 'SOFTWARE',\n",
       " 'COMMODITY',\n",
       " 'EMPLOYEE',\n",
       " 'LAND',\n",
       " 'PACE',\n",
       " 'OPPOSITION',\n",
       " 'BURNHAM',\n",
       " 'MILES',\n",
       " 'FUNDING',\n",
       " 'MRS.',\n",
       " 'SALOMON',\n",
       " 'S.',\n",
       " 'MANHATTAN',\n",
       " 'OFFICES',\n",
       " 'BOOKS',\n",
       " 'W.',\n",
       " \"'S\",\n",
       " 'AMOUNTS',\n",
       " 'THOUSANDS',\n",
       " 'WATER',\n",
       " 'REASONS',\n",
       " 'POSSIBILITY',\n",
       " 'RECOVERY',\n",
       " 'EXPERTS',\n",
       " 'CRITICS',\n",
       " 'LAMBERT',\n",
       " 'HEART',\n",
       " 'PLAYERS',\n",
       " 'AUTHORITIES',\n",
       " 'KONG',\n",
       " 'NONE',\n",
       " 'JACK',\n",
       " 'RALLY',\n",
       " 'NO.',\n",
       " 'OHIO',\n",
       " 'CUSTOMER',\n",
       " 'REAGAN',\n",
       " 'JAN.',\n",
       " 'COLUMBIA',\n",
       " 'ACCORD',\n",
       " 'CALL',\n",
       " '3\\\\',\n",
       " 'GOLD',\n",
       " 'AGENCIES',\n",
       " 'POUND',\n",
       " 'UNCERTAINTY',\n",
       " 'CITIES',\n",
       " 'TRADER',\n",
       " 'STEPHEN',\n",
       " 'EFFECTS',\n",
       " 'LTD',\n",
       " 'MANUFACTURER',\n",
       " 'THEN',\n",
       " 'LIGHT',\n",
       " 'EDWARD',\n",
       " 'U.K.',\n",
       " 'PLUNGE',\n",
       " 'EXPORTS',\n",
       " 'JOSEPH',\n",
       " 'CREDITORS',\n",
       " 'DECISIONS',\n",
       " 'SIDES',\n",
       " 'MASS.',\n",
       " 'NUMBERS',\n",
       " 'CLASS',\n",
       " 'SWINGS',\n",
       " 'DIVIDENDS',\n",
       " 'START',\n",
       " 'MILLIONS',\n",
       " 'ANY',\n",
       " 'RULE',\n",
       " 'REACTION',\n",
       " 'TOP',\n",
       " 'REPRESENTATIVES',\n",
       " 'BIDS',\n",
       " 'TORONTO',\n",
       " 'CLIENT',\n",
       " 'THREAT',\n",
       " 'AGREEMENTS',\n",
       " 'DECLINES',\n",
       " 'TELECOMMUNICATIONS',\n",
       " 'POLITICS',\n",
       " 'FEET',\n",
       " 'WEEKEND',\n",
       " 'COMMENTS',\n",
       " 'REORGANIZATION',\n",
       " 'CONNECTION',\n",
       " 'GREAT',\n",
       " 'REGION',\n",
       " 'H.',\n",
       " 'ADS',\n",
       " 'DIFFERENCES',\n",
       " 'SOCIETY',\n",
       " 'UAL',\n",
       " 'A',\n",
       " 'EMPLOYMENT',\n",
       " 'MINISTRY',\n",
       " 'HOUR',\n",
       " 'DOZEN',\n",
       " \"'\",\n",
       " 'CORPORATIONS',\n",
       " 'HEADQUARTERS',\n",
       " 'REQUEST',\n",
       " 'THIRD',\n",
       " 'PIECE',\n",
       " 'HOPE',\n",
       " 'IMPROVEMENT',\n",
       " 'LENDING',\n",
       " 'SEASON',\n",
       " 'CIRCUMSTANCES',\n",
       " 'FOREIGN',\n",
       " 'JERSEY',\n",
       " 'DEATH',\n",
       " 'SLOWDOWN',\n",
       " 'EDITOR',\n",
       " 'DEMOCRATS',\n",
       " 'HUNDREDS',\n",
       " 'DEVICES',\n",
       " 'SUPREME',\n",
       " 'RETIREMENT',\n",
       " 'PENCE',\n",
       " 'FOUNDER',\n",
       " 'REFORM',\n",
       " 'PENSION',\n",
       " 'NATURE',\n",
       " 'RUMORS',\n",
       " 'TO',\n",
       " 'BIT',\n",
       " 'N.Y.',\n",
       " 'DEPOSIT',\n",
       " 'ROOM',\n",
       " 'EXPRESS',\n",
       " 'LESS',\n",
       " 'S.A.',\n",
       " 'MOMENT',\n",
       " 'COUNTY',\n",
       " 'BROWN',\n",
       " 'CRIME',\n",
       " 'YIELDS',\n",
       " 'FAILURE',\n",
       " 'MARGINS',\n",
       " 'AS',\n",
       " 'THRIFT',\n",
       " 'RESIGNATION',\n",
       " 'CENTURY',\n",
       " 'FRAUD',\n",
       " 'CONFIDENCE',\n",
       " 'COLLEGE',\n",
       " 'LEADERSHIP',\n",
       " 'SUBJECT',\n",
       " 'BROADCASTING',\n",
       " 'COUNSEL',\n",
       " 'WAKE',\n",
       " 'BUYER',\n",
       " 'STYLE',\n",
       " 'PRICING',\n",
       " 'POLITICIANS',\n",
       " 'VERSION',\n",
       " 'RELATIONSHIP',\n",
       " 'STORE',\n",
       " 'MIND',\n",
       " 'PROSPECTS',\n",
       " 'WORD',\n",
       " 'CONN.',\n",
       " 'FORECASTS',\n",
       " 'EXPORT',\n",
       " 'ARBITRAGE',\n",
       " 'WESTERN',\n",
       " 'CRISIS',\n",
       " 'RESPONSIBILITY',\n",
       " 'FEAR',\n",
       " 'PAY',\n",
       " 'HELP',\n",
       " 'IMPORTS',\n",
       " 'HEARING',\n",
       " 'INSTRUMENTS',\n",
       " 'PANEL',\n",
       " 'PHILADELPHIA',\n",
       " 'DONALD',\n",
       " 'MINUTES',\n",
       " 'POLICE',\n",
       " 'NAMES',\n",
       " 'PROVISIONS',\n",
       " 'UTILITY',\n",
       " 'EMERGENCY',\n",
       " 'AIRCRAFT',\n",
       " 'BENEFIT',\n",
       " 'EVERYBODY',\n",
       " 'FRANK',\n",
       " 'WORDS',\n",
       " 'LOOK',\n",
       " 'OUTLOOK',\n",
       " 'LEAST',\n",
       " 'CHINA',\n",
       " 'HOPES',\n",
       " 'ADVANTAGE',\n",
       " 'BIDDING',\n",
       " 'AUG.',\n",
       " 'BOTH',\n",
       " 'WAGE',\n",
       " 'STRUCTURE',\n",
       " 'RATING',\n",
       " 'ALTERNATIVES',\n",
       " 'MACHINE',\n",
       " 'SEATS',\n",
       " 'TENDER',\n",
       " 'CRITICISM',\n",
       " 'SPECIALTY',\n",
       " 'FIRE',\n",
       " 'FEBRUARY',\n",
       " 'AG',\n",
       " 'EVENT',\n",
       " 'MODELS',\n",
       " '&',\n",
       " 'SOVIETS',\n",
       " 'ADVANCE',\n",
       " 'DALLAS',\n",
       " 'F.',\n",
       " 'OUTPUT',\n",
       " 'PACT',\n",
       " 'FACTOR',\n",
       " 'OBSERVERS',\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs = init_vocab(filelist=\"wsj.train_dev\")\n",
    "len(vocabs)\n",
    "vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_eTrans_with_Word(sent, vocabs):\n",
    "    x = sent.split()\n",
    "    #print(x)\n",
    "    length = len(x)\n",
    "    #print(length)\n",
    "    e_occur = x.count('X') + x.count('S') + x.count('O') #counting the number of occurrence of entities\n",
    "    #print(e_occur)\n",
    "    if length > 80:\n",
    "        if e_occur < 3:\n",
    "            return \"\"\n",
    "    elif length > 20:\n",
    "        if e_occur < 2:\n",
    "            return \"\"\n",
    "    \n",
    "    ent = x[0]\n",
    "    #print(ent)\n",
    "    x = x[1:]\n",
    "    \n",
    "    new_x = []\n",
    "\n",
    "    for role in x:\n",
    "        if role != \"-\":\n",
    "            if ent in vocabs:\n",
    "                new_x.append(ent+\"_\"+role)\n",
    "            else:\n",
    "                new_x.append(\"ovv_\"+ role)\n",
    "                \n",
    "        else:\n",
    "            new_x.append(\"-\")\n",
    "\n",
    "    #print(new_x)\n",
    "    return ' '.join(new_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- - - - - - - - - - - - - - - CITY_X - CITY_X CITY_X - CITY_X CITY_X CITY_X - - - - CITY_S - - - - - - - - - - - - - -'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_eTrans_with_Word(\"CITY - - - - - - - - - - - - - - - X - X X - X X X - - - - S - - - - - - - - - - - - - -\", vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def numberize_sentences(sentences, vocab_idmap):  \n",
    "\n",
    "    sentences_id=[]  \n",
    "\n",
    "    for sid, sent in enumerate (sentences):\n",
    "        tmp_list = []\n",
    "        #print(sid)\n",
    "        for wrd in sent.split():\n",
    "            if wrd in vocab_idmap:\n",
    "                wrd_id = vocab_idmap[wrd]  \n",
    "            else:\n",
    "                wrd_id = 0\n",
    "            tmp_list.append(wrd_id)\n",
    "            #print(tmp_list)\n",
    "        sentences_id.append(tmp_list)\n",
    "\n",
    "    return sentences_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjust_index(X, maxlen=None, window_size=3):\n",
    "\n",
    "    if maxlen: # exclude tweets that are larger than maxlen\n",
    "        new_X = []\n",
    "        for x in X:\n",
    "\n",
    "            if len(x) > maxlen:\n",
    "                #print(\"************* Maxlen of whole dataset: \" + str(len(x)) )\n",
    "            \ttmp = x[0:maxlen]\n",
    "            \ttmp[maxlen-window_size:maxlen] = ['0'] * window_size\n",
    "            \tnew_X.append(tmp)\n",
    "            else:\n",
    "                new_X.append(x)\n",
    "\n",
    "        X = new_X\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_numberize_egrids(filelist=\"list_of_grid.txt\", maxlen=10000, w_size=3, E=None, vocabs=None, emb_size=300, perm_num=20):\n",
    "    # loading entiry-grid data from list of pos document and list of neg document\n",
    "    if vocabs is None:\n",
    "        print(\"Please input vocab list\")\n",
    "        return None\n",
    "\n",
    "    list_of_files = [line.rstrip('\\n') for line in open(filelist)]\n",
    "    #print(list_of_files)\n",
    "\n",
    "    # process postive gird, convert each file to be a sentence\n",
    "    sentences_1 = []\n",
    "    sentences_0 = []\n",
    "    #print(len(list_of_files))\n",
    "    for file in list_of_files:\n",
    "        #print(file) \n",
    "\n",
    "        lines = [line.rstrip('\\n') for line in open(file + \".EGrid\")]\n",
    "        #f_lines = [line.rstrip('\\n') for line in open(file + \".Feats\")]\n",
    "\n",
    "        grid_1 = \"0 \"* w_size\n",
    "        #print(grid_1)\n",
    "        for idx, line in enumerate(lines):\n",
    "            #print(line)\n",
    "            e_trans = get_eTrans_with_Word(line, vocabs) # merge the grid of positive document  \n",
    "            if len(e_trans) !=0:\n",
    "                #print e_trans\n",
    "                grid_1 = grid_1 + e_trans + \" \" + \"0 \"* w_size\n",
    "        #print(grid_1)\n",
    "        #print(\"*********************************************************\")\n",
    "        \n",
    "        p_count = 0\n",
    "        for i in range(1,perm_num+1): # reading the permuted docs\n",
    "            permuted_lines = [p_line.rstrip('\\n') for p_line in open(file+ \".EGrid\" +\"-\"+str(i))]    \n",
    "            grid_0 = \"0 \"* w_size\n",
    "\n",
    "            for idx, p_line in enumerate(permuted_lines):\n",
    "                e_trans_0 = get_eTrans_with_Word(p_line, vocabs)\n",
    "                if len(e_trans_0) !=0:\n",
    "                    grid_0 = grid_0 + e_trans_0  + \" \" + \"0 \"* w_size\n",
    "\n",
    "            if grid_0 != grid_1: #check the duplication\n",
    "                p_count = p_count + 1\n",
    "                sentences_0.append(grid_0)\n",
    "            #else:\n",
    "            #    print(file+ \".EGrid\" +\"-\"+str(i)) // print duplicates permuted docs with original\n",
    "        \n",
    "        for i in range (0, p_count): #stupid code\n",
    "            sentences_1.append(grid_1)\n",
    "        '''\n",
    "        print(sentences_0)\n",
    "        print(\"******************************************************************************\")\n",
    "        print(\"******************************************************************************\")\n",
    "        print(\"******************************************************************************\")\n",
    "        print(\"******************************************************************************\")\n",
    "        print(\"******************************************************************************\")\n",
    "        print(sentences_1)\n",
    "        '''\n",
    "    \n",
    "    assert len(sentences_0) == len(sentences_1)\n",
    "    \n",
    "    vocab_x =[]\n",
    "    for ent in vocabs:\n",
    "        vocab_x.append(ent + \"_S\")\n",
    "        vocab_x.append(ent + \"_O\")\n",
    "        vocab_x.append(ent + \"_X\")\n",
    "\n",
    "    vocab_x.append(\"-\")\n",
    "    vocab_x.append(\"0\")\n",
    "    \n",
    "    #print(vocab_x)\n",
    "    #print(len(vocabs))\n",
    "    #print(len(vocab_x))\n",
    "    \n",
    "    vocab_idmap = {}\n",
    "    for i in range(len(vocab_x)):\n",
    "        vocab_idmap[vocab_x[i]] = i\n",
    "    #print(vocab_idmap)\n",
    "    #print(sentences_1)\n",
    "    \n",
    "    # Numberize the sentences\n",
    "    X_1 = numberize_sentences(sentences_1, vocab_idmap)\n",
    "    X_0  = numberize_sentences(sentences_0,  vocab_idmap)\n",
    "    #print(X_1)\n",
    "    \n",
    "    \n",
    "    X_1 = adjust_index(X_1, maxlen=maxlen, window_size=w_size)\n",
    "    X_0  = adjust_index(X_0,  maxlen=maxlen, window_size=w_size)\n",
    "\n",
    "    X_1 = sequence.pad_sequences(X_1, maxlen)\n",
    "    X_0 = sequence.pad_sequences(X_0, maxlen)\n",
    "\n",
    "\n",
    "    np.random.seed(2017)\n",
    "    E      = 0.01 * np.random.uniform( -1.0, 1.0, (len(vocab_x), emb_size))\n",
    "    E[len(vocab_x)-1] = 0\n",
    "    \n",
    "    return X_1, X_0, E\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "X_1, X_0, E = load_and_numberize_egrids(filelist=\"./final_data/wsj.dev\", maxlen=2000, w_size=6, vocabs=vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0095808 ,  0.0053414 , -0.0010416 , ..., -0.00538052,\n",
       "        -0.00760095, -0.00241078],\n",
       "       [-0.00952895, -0.00265105,  0.00043136, ..., -0.00439773,\n",
       "        -0.00719359, -0.00841277],\n",
       "       [ 0.00661687,  0.00533594, -0.00848318, ..., -0.00893795,\n",
       "         0.00890061,  0.00605507],\n",
       "       ..., \n",
       "       [-0.00239471, -0.00426782, -0.00478336, ..., -0.005811  ,\n",
       "         0.00383426, -0.00889049],\n",
       "       [ 0.00123934,  0.0052735 , -0.00486173, ..., -0.00560788,\n",
       "        -0.00919979,  0.0041078 ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17914, 17914, 17914, ...,     0,     0,     0],\n",
       "       [17914, 17914, 17914, ...,     0,     0,     0],\n",
       "       [17914, 17914, 17914, ...,     0,     0,     0],\n",
       "       ..., \n",
       "       [    0,     0,     0, ..., 17914, 17914, 17914],\n",
       "       [    0,     0,     0, ..., 17914, 17914, 17914],\n",
       "       [    0,     0,     0, ..., 17914, 17914, 17914]], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17914, 17914, 17914, ...,     0,     0,     0],\n",
       "       [17914, 17914, 17914, ...,     0,     0,     0],\n",
       "       [17914, 17914, 17914, ...,     0,     0,     0],\n",
       "       ..., \n",
       "       [    0,     0,     0, ..., 17914, 17914, 17914],\n",
       "       [    0,     0,     0, ..., 17914, 17914, 17914],\n",
       "       [    0,     0,     0, ..., 17914, 17914, 17914]], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17915, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get entity transition from a row of Entity Grid\n",
    "def get_eTrans_with_Feats(sent=\"\",feats=\"\",fn=None):\n",
    "    x = sent.split()\n",
    "    #print(x)\n",
    "    length = len(x)\n",
    "    e_occur = x.count('X') + x.count('S') + x.count('O') #counting the number of occurrence of entities\n",
    "    #print(e_occur)\n",
    "    if length > 80:\n",
    "        if e_occur < 3:\n",
    "            return \"\"\n",
    "    elif length > 20:\n",
    "        if e_occur < 2:\n",
    "            return \"\"\n",
    "    \n",
    "    if fn==None: #coherence model without features\n",
    "        x = x[1:]\n",
    "        return ' '.join(x)     \n",
    "\n",
    "    f = feats.split()\n",
    "    #print(f)\n",
    "    #print(x[0] + \" -- \" + f[0])\n",
    "    assert f[0] == x[0] # checking working on the same entity \n",
    "    #print(x[0] + \" -- \" + f[0])\n",
    "    #print(x)\n",
    "    #print(f)\n",
    "    \n",
    "    x = x[1:]\n",
    "    f = f[1:]\n",
    "    x_f = []\n",
    "    \n",
    "    for sem_role in x:\n",
    "        new_role = sem_role;\n",
    "        if new_role != '-':\n",
    "            for i in fn:\n",
    "                #print(i)\n",
    "                if i == 0: #adding salience\n",
    "                    if e_occur == 1:\n",
    "                        new_role = new_role + \"F01\"\n",
    "                    elif e_occur == 2:\n",
    "                        new_role = new_role + \"F02\"\n",
    "                    elif e_occur == 3:\n",
    "                        new_role = new_role + \"F03\"\n",
    "                    elif e_occur >3 :\n",
    "                        new_role = new_role + \"F04\"\n",
    "                    \n",
    "                else:\n",
    "                    #print(\"hello\")\n",
    "                    #print(f[i-1])\n",
    "                    new_role = new_role + \"F\" + str(i) + f[i-1] # num feat = idx + 1\n",
    "  \n",
    "        x_f.append(new_role)\n",
    "\n",
    "    return ' '.join(x_f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'XF01F10F31 -'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_eTrans_with_Feats(sent='                NOV. X -', feats='                                    NOV. 0 0 1 0 0 1 0 1 1', fn=[0, 1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#get entity transition from a row of Entity Grid for insertion experiment\n",
    "def get_eTrans_With_Perm(sent=\"\",feats=\"\",fn=None, perm=[]):\n",
    "    #print(feats)\n",
    "    #print(perm)\n",
    "\n",
    "    x = sent.split()\n",
    "    x = x[1:]\n",
    "    length = len(x)\n",
    "    e_occur = x.count('X') + x.count('S') + x.count('O') #counting the number of coocurence of the entity\n",
    "    if length > 80:\n",
    "        if e_occur < 3:\n",
    "            return \"\"\n",
    "    elif length > 20:\n",
    "        if e_occur < 2:\n",
    "            return \"\"\n",
    "    #need to re-order the entity meaning re-order sentence in a document\n",
    "    p_x = []\n",
    "    for i in perm:\n",
    "        p_x.append(x[i])\n",
    "\n",
    "    if fn==None: #coherence model without features\n",
    "       return ' '.join(p_x)\n",
    "\n",
    "\n",
    "    f = feats.split()\n",
    "    f = f[1:]\n",
    "\n",
    "    p_x_f = []\n",
    "    for sem_role in p_x: # extended coherence model without features\n",
    "        new_role = sem_role;\n",
    "        if new_role != '-':\n",
    "            for i in fn:\n",
    "                if i ==0 : #adding salience\n",
    "                    if e_occur == 1:\n",
    "                        new_role = new_role + \"F01\"\n",
    "                    elif e_occur == 2:\n",
    "                        new_role = new_role + \"F02\"\n",
    "                    elif e_occur == 3:\n",
    "                        new_role = new_role + \"F03\"\n",
    "                    elif e_occur >3 :\n",
    "                        new_role = new_role + \"F04\"\n",
    "                else:\n",
    "                    new_role = new_role + \"F\" + str(i) + f[i-1] # num feat = idx + 1\n",
    "  \n",
    "        p_x_f.append(new_role)\n",
    "\n",
    "    return ' '.join(p_x_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_POS_EGrid(filename=\"\", w_size=3, maxlen=1000, vocab_list=None , fn=None ):\n",
    "    lines = [line.rstrip('\\n') for line in open(filename + \".EGrid\")]\n",
    "    f_lines = [line.rstrip('\\n') for line in open(filename + \".Feats\")]\n",
    "    #print(lines)\n",
    "    #print(\"***********************************\")\n",
    "    #print(f_lines)\n",
    "\n",
    "    grid_1 = \"0 \"* w_size\n",
    "    for idx, line in enumerate(lines):\n",
    "        # merge the grid of positive document \n",
    "        e_trans = get_eTrans_with_Feats(sent=line, feats=f_lines[idx], fn=fn)\n",
    "        if len(e_trans) !=0:\n",
    "            grid_1 = grid_1 + e_trans + \" \" + \"0 \"* w_size\n",
    "            #print(e_trans)\n",
    "    #print(grid_1)\n",
    "    vocab_idmap = {}\n",
    "    for i in range(len(vocab_list)):\n",
    "        vocab_idmap[vocab_list[i]] = i\n",
    "\n",
    "    X_1 = numberize_sentences([grid_1], vocab_idmap)\n",
    "    X_1 = adjust_index(X_1, maxlen=maxlen, window_size=w_size)\n",
    "    X_1 =  sequence.pad_sequences(X_1, maxlen)\n",
    "\n",
    "    return X_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['                NOV. X -', '              PIERRE X -', '              VINKEN S S', '               YEARS X -', '               BOARD O -', '            DIRECTOR X -', '                 MR. - X', '            CHAIRMAN - O', '            ELSEVIER - X', '                N.V. - X', '          PUBLISHING - X', '               GROUP - X']\n",
      "***********************************\n",
      "['                                    NOV. 0 0 1 0 0 1 0 1 1', '                                  PIERRE 0 0 1 0 0 1 0 0 0', '                                  VINKEN 0 0 1 1 0 0 0 1 1', '                                   YEARS 1 1 0 0 0 1 0 1 1', '                                   BOARD 0 1 0 0 0 1 0 1 1', '                                DIRECTOR 0 0 0 0 0 1 0 1 1', '                                     MR. 0 0 1 0 0 0 0 0 0', '                                CHAIRMAN 1 1 0 0 0 1 0 1 1', '                                ELSEVIER 0 0 1 0 0 0 0 0 0', '                                    N.V. 0 0 1 0 0 0 0 1 1', '                              PUBLISHING 0 0 0 0 0 1 0 0 0', '                                   GROUP 1 1 0 0 0 1 0 1 0']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-969b1802855e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mload_POS_EGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./final_data/EGrid.train_dev/wsj_0001.pos.text.parsed.ner\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-d00805cfe2e6>\u001b[0m in \u001b[0;36mload_POS_EGrid\u001b[0;34m(filename, w_size, maxlen, vocab_list, fn)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#print(grid_1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mvocab_idmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mvocab_idmap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvocab_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "load_POS_EGrid(filename=\"./final_data/EGrid.train_dev/wsj_0001.pos.text.parsed.ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_NEG_EGrid(filename=\"\", w_size=3, maxlen=1000,  vocab_list=None, fn=None, perm=None):\n",
    "    #print(perm)\n",
    "    if perm != None:\n",
    "        lines = [line.rstrip('\\n') for line in open(filename + \".EGrid\")]\n",
    "        f_lines = [line.rstrip('\\n') for line in open(filename + \".Feats\")]\n",
    "\n",
    "\n",
    "        grid_0 = \"0 \"* w_size\n",
    "        for idx, line in enumerate(lines):\n",
    "            #print(line)\n",
    "            e_trans_0 = get_eTrans_With_Perm(sent=line,feats=f_lines[idx],fn=fn, perm=perm) # need to include features\n",
    "            if len(e_trans_0) !=0:\n",
    "                grid_0 = grid_0 + e_trans_0  + \" \" + \"0 \"* w_size\n",
    "            #print(e_trans_0)\n",
    "        \n",
    "        #print(grid_0)\n",
    "        vocab_idmap = {}\n",
    "        for i in range(len(vocab_list)):\n",
    "            vocab_idmap[vocab_list[i]] = i\n",
    "\n",
    "        X_0 = numberize_sentences([grid_0], vocab_idmap)\n",
    "        X_0 = adjust_index(X_0, maxlen=maxlen, window_size=w_size)\n",
    "        X_0 = sequence.pad_sequences(X_0, maxlen)\n",
    "\n",
    "        return X_0\n",
    "\n",
    "    else:\n",
    "        print(\"no permuted list\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_all(filelist=\"list_of_grid.txt\",fn=None):\n",
    "\n",
    "    list_of_files = [line.rstrip('\\n') for line in open(filelist)]\n",
    "    print(\"Using features: \" + str(fn))\n",
    "    vocab = Counter()\n",
    "\n",
    "    for file in list_of_files:\n",
    "#        print(file)\n",
    "        lines = [line.rstrip('\\n') for line in open(file + \".EGrid\")]\n",
    "        f_lines = [line.rstrip('\\n') for line in open(file + \".Feats\")]\n",
    "\n",
    "        for idx, line in enumerate(lines):\n",
    "            # merge the grid of positive document \n",
    "            e_trans = get_eTrans_with_Feats(sent=line,feats=f_lines[idx],fn=fn)\n",
    "            # need to update the dictionary here\n",
    "            if len(e_trans) !=0:\n",
    "                for wrd in e_trans.split():\n",
    "                    vocab[wrd] += 1\n",
    "\n",
    "    vocab = dict (vocab)\n",
    "    vocab_list = sorted (vocab.keys())\n",
    "    vocab_list.append('0')\n",
    "    print( \"Total vocabulary size in the whole dataset: \" + str (len(vocab)))\n",
    "\n",
    "    return vocab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using features: [0, 1, 3]\n",
      "Total vocabulary size in the whole dataset: 49\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['-',\n",
       " 'OF01F10F30',\n",
       " 'OF01F10F31',\n",
       " 'OF01F11F30',\n",
       " 'OF01F11F31',\n",
       " 'OF02F10F30',\n",
       " 'OF02F10F31',\n",
       " 'OF02F11F30',\n",
       " 'OF02F11F31',\n",
       " 'OF03F10F30',\n",
       " 'OF03F10F31',\n",
       " 'OF03F11F30',\n",
       " 'OF03F11F31',\n",
       " 'OF04F10F30',\n",
       " 'OF04F10F31',\n",
       " 'OF04F11F30',\n",
       " 'OF04F11F31',\n",
       " 'SF01F10F30',\n",
       " 'SF01F10F31',\n",
       " 'SF01F11F30',\n",
       " 'SF01F11F31',\n",
       " 'SF02F10F30',\n",
       " 'SF02F10F31',\n",
       " 'SF02F11F30',\n",
       " 'SF02F11F31',\n",
       " 'SF03F10F30',\n",
       " 'SF03F10F31',\n",
       " 'SF03F11F30',\n",
       " 'SF03F11F31',\n",
       " 'SF04F10F30',\n",
       " 'SF04F10F31',\n",
       " 'SF04F11F30',\n",
       " 'SF04F11F31',\n",
       " 'XF01F10F30',\n",
       " 'XF01F10F31',\n",
       " 'XF01F11F30',\n",
       " 'XF01F11F31',\n",
       " 'XF02F10F30',\n",
       " 'XF02F10F31',\n",
       " 'XF02F11F30',\n",
       " 'XF02F11F31',\n",
       " 'XF03F10F30',\n",
       " 'XF03F10F31',\n",
       " 'XF03F11F30',\n",
       " 'XF03F11F31',\n",
       " 'XF04F10F30',\n",
       " 'XF04F10F31',\n",
       " 'XF04F11F30',\n",
       " 'XF04F11F31',\n",
       " '0']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_all(filelist=\"final_data/wsj.all\",fn=[0,1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
