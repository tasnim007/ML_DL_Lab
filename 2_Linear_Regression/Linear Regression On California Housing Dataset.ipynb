{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# California housing dataset\n",
    "\n",
    "The original database is available from StatLib\n",
    "\n",
    "    http://lib.stat.cmu.edu/\n",
    "\n",
    "The data contains 20,640 observations on 9 variables.\n",
    "\n",
    "This dataset contains the average house value as target variable\n",
    "and the following input variables (features): average income,\n",
    "housing average age, average rooms, average bedrooms, population,\n",
    "average occupation, latitude, and longitude in that order.\n",
    "\n",
    "#### References\n",
    "----------\n",
    "\n",
    "Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
    "Statistics and Probability Letters, 33 (1997) 291-297."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MedInc',\n",
       " 'HouseAge',\n",
       " 'AveRooms',\n",
       " 'AveBedrms',\n",
       " 'Population',\n",
       " 'AveOccup',\n",
       " 'Latitude',\n",
       " 'Longitude']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = fetch_california_housing()\n",
    "housing.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "print(housing.data.shape)\n",
    "print(housing.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Examples: 20640\n",
      "Number of features: 8\n"
     ]
    }
   ],
   "source": [
    "N, d = housing.data.shape\n",
    "print(\"Number of Examples: {}\".format(N))\n",
    "print(\"Number of features: {}\".format(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Normal Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 9)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "# Adding bias weight as 1 for every examples\n",
    "housing_data_plus_bias = np.c_[np.ones((N, 1)), housing.data] \n",
    "\n",
    "print(np.shape(housing_data_plus_bias))\n",
    "print(np.shape(housing.target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "\n",
    "W = tf.matmul(tf.matrix_inverse(tf.matmul(X, X, transpose_a=True)),tf.matmul(X,y,transpose_a = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted = tf.matmul(X, W)\n",
    "loss = tf.square(y - y_predicted, name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    W_values, l = sess.run([W, loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.74804688e+01],\n",
       "       [  4.35684204e-01],\n",
       "       [  9.33551788e-03],\n",
       "       [ -1.06575012e-01],\n",
       "       [  6.43951416e-01],\n",
       "       [ -4.26173210e-06],\n",
       "       [ -3.77273560e-03],\n",
       "       [ -4.26849365e-01],\n",
       "       [ -4.40734863e-01]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.5243528854015261\n"
     ]
    }
   ],
   "source": [
    "total_loss = np.sum(l)\n",
    "print(\"MSE: {}\".format(total_loss/N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we need to normalize the feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 20640)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((N, 1)), scaled_housing_data] #shape = [exampeles, features] \n",
    "scaled_housing_data_plus_bias = np.transpose(scaled_housing_data_plus_bias) #shape = [features, exampeles]\n",
    "\n",
    "#Now each column represents an example. It is done for our convenience.\n",
    "\n",
    "print(scaled_housing_data_plus_bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 20640)\n"
     ]
    }
   ],
   "source": [
    "housing_target_reshaped = np.transpose(housing.target.reshape(-1, 1))\n",
    "print(housing_target_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing_target_reshaped, dtype=tf.float32, name=\"y\")\n",
    "\n",
    "W = tf.Variable(tf.zeros([d + 1, 1]), name=\"weights\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = tf.matmul(W, X, transpose_a=True, name=\"predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = y - y_predicted\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 5.61049\n",
      "Epoch 100 MSE = 0.711395\n",
      "Epoch 200 MSE = 0.598105\n",
      "Epoch 300 MSE = 0.577228\n",
      "Epoch 400 MSE = 0.563226\n",
      "Epoch 500 MSE = 0.553028\n",
      "Epoch 600 MSE = 0.545566\n",
      "Epoch 700 MSE = 0.540093\n",
      "Epoch 800 MSE = 0.536071\n",
      "Epoch 900 MSE = 0.533108\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(optimizer)\n",
    "    \n",
    "    best_weights = W.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: \n",
      "[[ 2.06855249]\n",
      " [ 0.8390094 ]\n",
      " [ 0.14736038]\n",
      " [-0.23305154]\n",
      " [ 0.25675777]\n",
      " [ 0.00578232]\n",
      " [-0.04194649]\n",
      " [-0.6825164 ]\n",
      " [-0.65183544]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Weights: \")\n",
    "print(best_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "learning_rate = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(d + 1, 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([d + 1, 1]), name=\"weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted = tf.matmul(W, X, transpose_a=True, name=\"predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.square(y - y_predicted, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: [[ 4.01238585]]\n",
      "Epoch 1: [[ 2.12409425]]\n",
      "Epoch 2: [[ 1.29115784]]\n",
      "Epoch 3: [[ 0.92067605]]\n",
      "Epoch 4: [[ 0.75361705]]\n",
      "Epoch 5: [[ 0.67636538]]\n",
      "Epoch 6: [[ 0.63895583]]\n",
      "Epoch 7: [[ 0.61938286]]\n",
      "Epoch 8: [[ 0.60790956]]\n",
      "Epoch 9: [[ 0.60022199]]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0\n",
    "        for i in range(N):\n",
    "            # Session runs train_op and fetch values of loss\n",
    "            _, l = sess.run([optimizer, loss], feed_dict={X : scaled_housing_data_plus_bias[:,i].reshape(-1,1), y : housing_target_reshaped[:,i]}) \n",
    "            total_loss += l\n",
    "        print('Epoch {0}: {1}'.format(epoch, total_loss/N))\n",
    "    \n",
    "    best_weights = W.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: \n",
      "[[ 2.02857256]\n",
      " [ 0.77524602]\n",
      " [ 0.20480497]\n",
      " [-0.00392454]\n",
      " [ 0.00435625]\n",
      " [ 0.01590534]\n",
      " [-0.03963242]\n",
      " [-0.26966438]\n",
      " [-0.24668297]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Weights: \")\n",
    "print(best_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Mini Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "learning_rate = 0.01\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(N / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(d + 1, batch_size), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(1, batch_size), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([d + 1, 1]), name=\"weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted = tf.matmul(W, X, transpose_a=True, name=\"predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.square(y - y_predicted, name=\"loss\")\n",
    "mse = tf.reduce_mean(loss, name = \"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index)  \n",
    "    indices = np.random.randint(N, size=batch_size)  \n",
    "    X_batch = scaled_housing_data_plus_bias[:, indices] \n",
    "    y_batch = housing_target_reshaped[:, indices] \n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.4975327253341675\n",
      "Epoch 1: 0.6461394429206848\n",
      "Epoch 2: 0.5028530359268188\n",
      "Epoch 3: 0.6780144572257996\n",
      "Epoch 4: 0.41529664397239685\n",
      "Epoch 5: 0.501575231552124\n",
      "Epoch 6: 0.35384222865104675\n",
      "Epoch 7: 0.39754387736320496\n",
      "Epoch 8: 0.6933445930480957\n",
      "Epoch 9: 0.3760089874267578\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            _, l = sess.run([optimizer, mse], feed_dict={X: X_batch, y: y_batch})\n",
    "        print('Epoch {0}: {1}'.format(epoch, l))\n",
    "        \n",
    "    best_weights = W.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: \n",
      "[[ 2.07018113]\n",
      " [ 0.84754699]\n",
      " [ 0.12223973]\n",
      " [-0.2771506 ]\n",
      " [ 0.35288864]\n",
      " [ 0.00471049]\n",
      " [-0.01249816]\n",
      " [-0.85162646]\n",
      " [-0.81841028]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Weights: \")\n",
    "print(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
